# ðŸ’¬ Overview
- get-in : btd paradox, digital signature susceptibility
- model of secure system
	- condition for perfect secrecy
    - shannon entroyphy
    - equivocation(ëª¨í˜¸ì„±)
    - perfect secrecy (Priori & Posterior Probability)
    - redundancy
    - unicity distance
- complexity theroy

# ðŸªœ Get in
## Birthday paradox
	about 50% change of having a same birthday when there are 23 people!

P(n) = prob that at least two have a same BTD when there are n persons

P(n) = 1 - P'(n)
(P'(n) = no one has same BTD)

P(1) = 1
P(2) = 1 \* (365-1)/365
P(3) = 1 \* (365-1)/365 \* (365-2)/365



## Digital Seignature Susceptibility
susceptibility : ë¯¼ê°ì„±
![](https://images.velog.io/images/yesterdaykite/post/a8a6327a-a3aa-4ab2-aa62-dc7209596796/image.png)


---
# ðŸ¦ Model of contents
![](https://images.velog.io/images/yesterdaykite/post/f0f3667d-5018-42a1-b7fe-3a61457aa8e9/image.png)

## âœ¨Shannon theory
__communication theory__ of secrecy system
![](https://images.velog.io/images/yesterdaykite/post/47a1f5e9-4ff7-4dfc-af5b-04d12ebeb1fc/image.png)
similar to __"noisy channel problem"__
i.e) A user wishing to send a message over a noisy channel __must add redundancy__ to allow __detection/correction of errors__.
- noisy channel : Mì„ ì „ì†¡í•˜ëŠ”ë°, ë…¸ì´ì¦ˆì— ì˜í•´ Cë¡œ ë³€í™”ëœ Mì„ ì—ëŸ¬íƒìƒ‰ê³¼ ìˆ˜ì •ì„ í†µí•´ ë‹¤ì‹œ Mìœ¼ë¡œ ìˆ˜ì •

## âœ¨PERFECT SECRECY - Priori & Posterior Probability

### âœ”ï¸ in words..
ì•”í˜¸í™”ë˜ê¸°ì „ (pri) Keyì˜ í™•ë¥ , Messageì˜ í™•ë¥ ê³¼
ì•”í˜¸í™” ëœ í›„ (post) ê³µê²©ìžê°€ cipher textë¥¼ í†µí•´ ê°€ëŠ¥í•œ keyì™€ messageë¥¼ ê³„ì‚°í•˜ëŠ” ê°€ëŠ¥ì„±

- __Pi : keyì˜ í™•ë¥ __ : A Kj is selected from the set of all keys K with probability Pi
- __Mj : Message ì˜ í™•ë¥ __ : A msg Mj is selected from the set of all msgs M with a priori probability Qj
(i.e. dataê°€ 16bitë©´ 2^16ê°€ì§€ì˜ msg ê²½ìš°ê°€ ìžˆë‹¤.)
- C = E(Mj, Ki)
=> __Cë¥¼ ê´€ì°°í•œ Attacker ëŠ” ê°€ëŠ¥í•œ Mjì™€ Kiì˜ postterior probabilityë¥¼ ê³„ì‚°í•  ìˆ˜ ìžˆë‹¤. __
=> posteriori probability = __attacker's knowledge__ë¥¼ represent


### âœ”ï¸ in calc..
![](https://images.velog.io/images/yesterdaykite/post/a31cb00f-dc97-4b54-bbae-6849112b00e2/image.png)
- P(M|C) = Cë¥¼ ì–»ì€ attackerê°€ ì œëŒ€ë¡œ Mì„ í•´ë…í•  í™•ë¥  = prob. of M given C intercepted
- P(C|M) = Mì— ì˜í•´ Cê°€ ìƒì„±ë  í™•ë¥  = prob. of C generated by M
- P(M) = Mì´ ì„ íƒë  í™•ë¥  = prob. of M being selected
- P(C) = Cê°€ ìž…ìˆ˜ë  í™•ë¥  = prob. of obtaing C



### âœ”ï¸ Condition for PERFECT SECRECY
> ðŸ¤” IF  __P(M|C) = P(M)__ for all C & M
__attacker gain NO info by intercepting C__

= cê°€ ê°•íƒˆë˜ì—ˆì„ë•Œì¡°ì°¨ Mì„ (ëžœë¤) ì„ íƒí•˜ëŠ” í™•ë¥ ê³¼ ê°™ë‹¤.
= cë¥¼ ê°•íƒˆí•´ë„ Mì— ëŒ€í•œ ì •ë³´ë¥¼ ì–»ëŠ” ê²ƒì´ ì—†ë‹¤

> ðŸ¤­ So __Perfect Securecy__ is
1. __P(M|C) = P(M)__ for all C & all M
2. __P(C|M) = P(C)__ for all C & all M

> ðŸ¤­ So __Perfect System__ is
=  __as many C's as M's__
= at least one K transforming any M into these C's.

this works for guessing imppossible XXD

these are neccessary and sufficient condition !

## âœ¨ Shannon Entropy
### âœ”ï¸ definition
> ![](https://images.velog.io/images/yesterdaykite/post/2534ad87-158b-495f-9b3f-4ac5aa82c413/image.png) __measure of unpredictability__ in random variable
(ë†’ì„ ìˆ˜ë¡ ì˜ˆì¸¡í•˜ê¸° íž˜ë“¤ë‹¤!)

### âœ”ï¸ Examples

1) Political Poll
- __Entrophy(H) is large : round 1__ - outcome of poll is not already known 'unpredictable'
	i.e.) Outcome of the poll and learning the result / gives / __some new info!__
- __Entrophy(H) is small :  round 2__ - _same poll_ performed after the first round
	i.e) outcome of the first-round poll / already known / and the second poll can be predicted.

2) Coin Flipping (fair coin case)
- Entropy(H) = 1 = ì „í˜€ ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥
- P(head) = P(tail) = no way to predict!


### âœ”ï¸ Calc..
> __Message Entrophy__
= amount of info produced / __when a message is chosen__
![](https://images.velog.io/images/yesterdaykite/post/89d790e7-dc21-4ed0-bda7-52055dab5b77/image.png)

> __Key Entropy__
= amount of info produced / __when a key is chosen__
![](https://images.velog.io/images/yesterdaykite/post/d4cc4ba2-d8ef-46a6-aae7-be4bc001f5e3/image.png)


### âœ”ï¸ Observation

- the amount of uncertainty introduced into the system / cannot be greater than the key uncertainty.

- K uncertanity is at least M uncertainty
__(Kì—”íŠ¸ë¡œí”¼ >= Mì—”íŠ¸ë¡œí”¼) =  M info is perfectly concealed
__
occurs when all M's are equally probable (i.e. totally random)


## âœ¨ equivocation(ëª¨í˜¸ì„±)
### âœ”ï¸ Definition
__Conditional entropies__ of K and M
(i.e., unpredictability of the K and M given an intercepted C.)
![](https://images.velog.io/images/yesterdaykite/post/186a88b1-9a29-4378-98b7-aa33c6c4869d/image.png)

### âœ”ï¸ Properties
> N = interceptedëœ C ì¼ë¶€ë¶„ ê¸¸ì´
__H(K, N|C) is a non-increasing function of N__

![](https://images.velog.io/images/yesterdaykite/post/d47c1523-7d9a-403a-864a-69c15d525537/image.png)
i.e., it's theoretically easier to determine the key as more C is intercepted. Cê°€ ë§Žì´ interceptë ìˆ˜ë¡ Kë¥¼ determine í•˜ê¸° ì‰¬ì›Œì§


### âœ”ï¸ For perfect secrecy!
__Mutual Info__
	- I(M|C) = Cê°€ ì£¼ì–´ì¡Œì„ë•Œ Mì— ëŒ€í•´ ì–»ì„ìˆ˜ìžˆëŠ” ì •ë³´ì˜ ì–‘
    - I(K|C) = Cê°€ ì£¼ì–´ì¡Œì„ë•Œ Kì— ëŒ€í•´ ì–»ì„ ìˆ˜ ìžˆëŠ” ì •ë³´ì˜ ì–‘

> I(M|C) = H(M) - H(M|C)

"new info revealed knowing C"
= "uncertainty" - "uncertainty after knowing C"


__How to achieve perfect secrecy?__
![](https://images.velog.io/images/yesterdaykite/post/cbe1eb6f-2387-4332-a3e4-d3c5d819513a/image.png)

> I(M|C) = H(M) - H(M|C) = 0
__H(M) = H(M|C)__

= __C and M are statistically independent__


also
> __H(M) <= H(K)__
= ì ì–´ë„ Kì—”íŠ¸ë¡œí”¼ëŠ” Mì—”íŠ¸ë¡œí”¼ë³´ë‹¤ ì»¤ì•¼!
= num of M bits <= num of K bits
since..
![](https://images.velog.io/images/yesterdaykite/post/d552ba62-c47f-4650-8581-d0d559f7d398/image.png)

otherwise,,
like H(M) > H(K) !
Cryptanalyst __can obtain a lot of info__ about plaintext.
![](https://images.velog.io/images/yesterdaykite/post/7127323c-2d40-427d-83b5-77d2ab2f1c3a/image.png)


